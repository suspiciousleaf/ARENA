import streamlit as st


def section():

    st.sidebar.markdown(r"""

## Table of Contents

<ul class="contents">
    <li class='margtop'><a class='contents-el' href='#non-differentiable-functions'>Non-Differentiable Functions</a></li>
    <li class='margtop'><a class='contents-el' href='#single-tensor-differentiable-functions'>Single-Tensor Differentiable Functions</a></li>
    <li><ul class="contents">
        <li><a class='contents-el' href='#exercise-negative'><b>Exercise</b> - <code>negative</code></a></li>
        <li><a class='contents-el' href='#exercise-exp'><b>Exercise</b> - <code>exp</code></a></li>
        <li><a class='contents-el' href='#exercise-reshape'><b>Exercise</b> - <code>reshape</code></a></li>
        <li><a class='contents-el' href='#exercise-permute'><b>Exercise</b> - <code>permute</code></a></li>
        <li><a class='contents-el' href='#exercise-expand'><b>Exercise</b> - <code>expand</code></a></li>
        <li><a class='contents-el' href='#exercise-sum'><b>Exercise</b> - <code>sum</code></a></li>
        <li><a class='contents-el' href='#exercise-indexing'><b>Exercise</b> - Indexing</a></li>
        <li><a class='contents-el' href='#elementwise-add-subtract-divide'>elementwise add, subtract, divide</a></li>
    </ul></li>
    <li class='margtop'><a class='contents-el' href='#in-place-operations'>In-Place Operations</a></li>
    <li class='margtop'><a class='contents-el' href='#mixed-scalar-tensor-operations'>Mixed Scalar-Tensor Operations</a></li>
    <li><ul class="contents">
        <li><a class='contents-el' href='#exercise-max'><b>Exercise</b> - <code>max</code></a></li>
        <li><a class='contents-el' href='#exercise-functional-relu'><b>Exercise</b> - functional <code>ReLU</code></a></li>
        <li><a class='contents-el' href='#exercise-10d-matmul'><b>Exercise</b> - 2D <code>matmul</code></a></li>
</ul>""", unsafe_allow_html=True)

    st.markdown(
r"""

# More forward & backward functions


> ### Learning Objectives
>
> * Implement more forward and backward functions, including for 
>   * Indexing
>   * Non-differentiable functions
>   * Matrix multiplication


Congrats on implementing backprop! The next thing we'll do is write implement a bunch of backward functions that we need to train our model at the end of the day, as well as ones that cover interesting cases.

These should be just like your `log_back` and `multiply_back0`, `multiplyback1` examples earlier.


***Note - some of these exercises can get a bit repetitive. About 60% of the value of these exercises was in the first 2 sections out of 5, and of the remaining 40%, not much of it is in this section! So you're welcome to skim through these exercises if you don't find them interesting.***


## Non-Differentiable Functions

For functions like `torch.argmax` or `torch.eq`, there's no sensible way to define gradients with respect to the input tensor. For these, we will still use `wrap_forward_fn` because we still need to unbox the arguments and box the result, but by passing `is_differentiable=False` we can avoid doing any unnecessary computation.

We've given you this one as an example:


```python
def _argmax(x: Arr, dim=None, keepdim=False):
    '''Like torch.argmax.'''
    return np.expand_dims(np.argmax(x, axis=dim), axis=([] if dim is None else dim))



argmax = wrap_forward_fn(_argmax, is_differentiable=False)

a = Tensor([1.0, 0.0, 3.0, 4.0], requires_grad=True)
b = a.argmax()
assert not b.requires_grad
assert b.recipe is None
assert b.item() == 3
```

## Single-Tensor Differentiable Functions


### Exercise - `negative`

```yaml
Difficulty: ðŸ”´âšªâšªâšªâšª
Importance: ðŸ”µâšªâšªâšªâšª

You should spend up to 5-10 minutes on this exercise.
```

`torch.negative` just performs `-x` elementwise. Make your own version `negative` using `wrap_forward_fn`.


```python
def negative_back(grad_out: Arr, out: Arr, x: Arr) -> Arr:
    '''Backward function for f(x) = -x elementwise.'''
    pass


negative = wrap_forward_fn(np.negative)
BACK_FUNCS.add_back_func(np.negative, 0, negative_back)

tests.test_negative_back(Tensor)
```

<details>
<summary>Solution</summary>


```python
def negative_back(grad_out: Arr, out: Arr, x: Arr) -> Arr:
    '''Backward function for f(x) = -x elementwise.'''
    # SOLUTION
    return unbroadcast(-grad_out, x)
```
</details>


### Exercise - `exp`

```yaml
Difficulty: ðŸ”´âšªâšªâšªâšª
Importance: ðŸ”µðŸ”µâšªâšªâšª

You should spend up to 5-10 minutes on this exercise.
```

Make your own version of `torch.exp`. The backward function should express the result in terms of the `out` parameter - this more efficient than expressing it in terms of `x`.


```python
def exp_back(grad_out: Arr, out: Arr, x: Arr) -> Arr:
    pass


exp = wrap_forward_fn(np.exp)
BACK_FUNCS.add_back_func(np.exp, 0, exp_back)

tests.test_exp_back(Tensor)
```

<details>
<summary>Solution</summary>


```python
def exp_back(grad_out: Arr, out: Arr, x: Arr) -> Arr:
    # SOLUTION
    return out * grad_out
```
</details>


### Exercise - `reshape`

```yaml
Difficulty: ðŸ”´âšªâšªâšªâšª
Importance: ðŸ”µâšªâšªâšªâšª

You should spend up to 5-10 minutes on this exercise.
```

`reshape` is a bit more complicated than the many functions we've dealt with so far: there is an additional positional argument `new_shape`. Since it's not a `Tensor`, we don't need to think about differentiating with respect to it. Remember, `new_shape` is the argument that gets passed into the **forward function**, and we're trying to reverse this operation and return to the shape of the input.

Depending how you wrote `wrap_forward_fn` and `backprop`, you might need to go back and adjust them to handle this. Or, you might just have to implement `reshape_back` and everything will work. 

Note that the output is a different shape than the input, but this doesn't introduce any additional complications.


```python
def reshape_back(grad_out: Arr, out: Arr, x: Arr, new_shape: tuple) -> Arr:
    pass


reshape = wrap_forward_fn(np.reshape)
BACK_FUNCS.add_back_func(np.reshape, 0, reshape_back)

tests.test_reshape_back(Tensor)
```

<details>
<summary>Solution</summary>


```python
def reshape_back(grad_out: Arr, out: Arr, x: Arr, new_shape: tuple) -> Arr:
    # SOLUTION
    return np.reshape(grad_out, x.shape)
```
</details>


### Exercise - `permute`

```yaml
Difficulty: ðŸ”´ðŸ”´ðŸ”´âšªâšª
Importance: ðŸ”µâšªâšªâšªâšª

You should spend up to 10-15 minutes on this exercise.
```

In NumPy, the equivalent of `torch.permute` is called `np.transpose`, so we will wrap that.


```python
def invert_transposition(axes: tuple) -> tuple:
    '''
    axes: tuple indicating a transition
    
    Returns: inverse of this transposition, i.e. the array `axes_inv` s.t. we have:
        np.transpose(np.transpose(x, axes), axes_inv) == x
    
    Some examples:
        (1, 0)    --> (1, 0)     # this is reversing a simple 2-element transposition
        (0, 2, 1) --> (0, 1, 2)
        (1, 2, 0) --> (2, 0, 1)  # this is reversing the order of a 3-cycle
    '''
    pass

def permute_back(grad_out: Arr, out: Arr, x: Arr, axes: tuple) -> Arr:
    return np.transpose(grad_out, invert_transposition(axes))



BACK_FUNCS.add_back_func(np.transpose, 0, permute_back)
permute = wrap_forward_fn(np.transpose)

tests.test_permute_back(Tensor)
```

<details>
<summary>Help - I'm confused about how to implement this function.</summary>

You should first define the function `invert_transposition`. A docstring is given below:

```python
def invert_transposition(axes: tuple) -> tuple:
    '''
    axes: tuple indicating a transition
    
    Returns: inverse of this transposition, i.e. the array `axes_inv` s.t. we have:
        np.transpose(np.transpose(x, axes), axes_inv) == x
    
    Some examples:
        (1, 0)    --> (1, 0)     # this is reversing a simple 2-element transposition
        (0, 2, 1) --> (0, 1, 2)
        (1, 2, 0) --> (2, 0, 1)  # this is reversing the order of a 3-cycle
    '''
    pass
```

Once you've done this, you can define `permute_back` by transposing again, this time with the inversed transposition instructions.
</details>

<details>
<summary>Solution</summary>


```python
def invert_transposition(axes: tuple) -> tuple:
    '''
    axes: tuple indicating a transition
    
    Returns: inverse of this transposition, i.e. the array `axes_inv` s.t. we have:
        np.transpose(np.transpose(x, axes), axes_inv) == x
    
    Some examples:
        (1, 0)    --> (1, 0)     # this is reversing a simple 2-element transposition
        (0, 2, 1) --> (0, 1, 2)
        (1, 2, 0) --> (2, 0, 1)  # this is reversing the order of a 3-cycle
    '''
    # SOLUTION
    
    # Slick solution:
    return tuple(np.argsort(axes))

    # Slower solution, which makes it clearer what operation is happening:
    reversed_transposition_map = {num: idx for (idx, num) in enumerate(axes)}
    reversed_transposition = [reversed_transposition_map[idx] for idx in range(len(axes))]
    return tuple(reversed_transposition)
```
</details>


### Exercise - `expand`

```yaml
Difficulty: ðŸ”´ðŸ”´ðŸ”´âšªâšª
Importance: ðŸ”µâšªâšªâšªâšª

You should spend up to 15-20 minutes on this exercise.
```

Implement your version of `torch.expand`. 

The backward function should just call `unbroadcast`. 

For the forward function, we will use `np.broadcast_to`. This function takes in an array and a target shape, and returns a version of the array broadcasted to the target shape using the rules of broadcasting we discussed in an earlier section. For example:


```python
x = np.array([1, 2, 3])

np.broadcast_to(x, (3, 3))
```

```python
x = np.array([[1], [2], [3]])

np.broadcast_to(x, (3, 3)) # x has shape (3, 1); broadcasting is done along rows
```

The reason we can't just use `np.broadcast_to` and call it a day is that `torch.expand` supports -1 for a dimension size meaning "don't change the size". For example:


```python
x = t.tensor([[1], [2], [3]])

x.expand(-1, 3)
```

So when implementing `_expand`, you'll need to be a bit careful when constructing the shape to broadcast to.


```python
def expand_back(grad_out: Arr, out: Arr, x: Arr, new_shape: tuple) -> Arr:
    return unbroadcast(grad_out, x)

def _expand(x: Arr, new_shape) -> Arr:
    '''
    Like torch.expand, calling np.broadcast_to internally.

    Note torch.expand supports -1 for a dimension size meaning "don't change the size".
    np.broadcast_to does not natively support this.
    '''
    pass


expand = wrap_forward_fn(_expand)
BACK_FUNCS.add_back_func(_expand, 0, expand_back)

tests.test_expand(Tensor)
tests.test_expand_negative_length(Tensor)
```

<details>
<summary>Help - I'm not sure how to construct the shape.</summary>

If `new_shape` contains no -1s, then you're done. If it does contain -1s, you want to replace those with the appropriate values from `x.shape`.

For example, if `a.shape = (5,)`, and `new_shape = (3, 2, -1)`, you want the actual shape passed into `np.broadcast_to` to be `(3, 2, 5)`.
</details>

<details>
<summary>Solution</summary>


```python
def _expand(x: Arr, new_shape) -> Arr:
    '''
    Like torch.expand, calling np.broadcast_to internally.

    Note torch.expand supports -1 for a dimension size meaning "don't change the size".
    np.broadcast_to does not natively support this.
    '''
    # SOLUTION
    
    n_added = len(new_shape) - x.ndim
    shape_non_negative = tuple([x.shape[i - n_added] if s == -1 else s for i, s in enumerate(new_shape)])
    return np.broadcast_to(x, shape_non_negative)
```
</details>


### Exercise - `sum`

```yaml
Difficulty: ðŸ”´ðŸ”´ðŸ”´âšªâšª
Importance: ðŸ”µðŸ”µâšªâšªâšª

You should spend up to 15-20 minutes on this exercise.
```

The output can also be smaller than the input, such as when calling `torch.sum`. Implement your own `torch.sum` and `sum_back`.

Note, if you get weird exceptions that you can't explain, and these exceptions don't even go away when you use the solutions provided, this probably means that your implementation of `wrap_forward_fn` was wrong in a way which wasn't picked up by the tests. You should return to this function and try to fix it (or just use the solution).


```python
def sum_back(grad_out: Arr, out: Arr, x: Arr, dim=None, keepdim=False):
    '''Basic idea: repeat grad_out over the dims along which x was summed'''
    pass

def _sum(x: Arr, dim=None, keepdim=False) -> Arr:
    '''Like torch.sum, calling np.sum internally.'''
    return np.sum(x, axis=dim, keepdims=keepdim)


sum = wrap_forward_fn(_sum)
BACK_FUNCS.add_back_func(_sum, 0, sum_back)

tests.test_sum_keepdim_false(Tensor)
tests.test_sum_keepdim_true(Tensor)
tests.test_sum_dim_none(Tensor)
```

<details>
<summary>Solution</summary>


```python
def sum_back(grad_out: Arr, out: Arr, x: Arr, dim=None, keepdim=False):
    '''Basic idea: repeat grad_out over the dims along which x was summed'''
    # SOLUTION
    
    # If grad_out is a scalar, we need to make it a tensor (so we can expand it later)
    if not isinstance(grad_out, Arr):
        grad_out = np.array(grad_out)
    
    # If dim=None, this means we summed over all axes, and we want to repeat back to input shape
    if dim is None:
        dim = list(range(x.ndim))
        
    # If keepdim=False, then we need to add back in dims, so grad_out and x have same number of dims
    if keepdim == False:
        grad_out = np.expand_dims(grad_out, dim)
    
    # Finally, we repeat grad_out along the dims over which x was summed
    return np.broadcast_to(grad_out, x.shape)
```
</details>


### Exercise - Indexing

```yaml
Difficulty: ðŸ”´ðŸ”´ðŸ”´âšªâšª
Importance: ðŸ”µðŸ”µâšªâšªâšª

You should spend up to 15-20 minutes on this exercise.
```

In its full generality, indexing a `torch.Tensor` is really complicated and there are quite a few cases to handle separately.

We only need two cases today:
- The index is an integer or tuple of integers.
- The index is a tuple of (array or Tensor) representing coordinates. Each array is 1D and of equal length. Some coordinates may be repeated. This is [Integer array indexing](https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing).
    - For example, to select the five elements at (0, 0), (1,0), (0, 1), (1, 2), and (0, 0), the index would be the tuple `(np.array([0, 1, 0, 1, 0]), np.array([0, 0, 1, 2, 0]))`. 

Note, in `_getitem` you'll need to deal with one special case: when `index` is of type signature `tuple[Tensor]`. If not for this case, `return x[index]` would suffice for this function. You should define a `coerce_index` function to deal with this particular case; we've provided a docstring for this purpose.


```python
Index = Union[int, Tuple[int, ...], Tuple[Arr], Tuple[Tensor]]
    
def coerce_index(index: Index) -> Union[int, Tuple[int, ...], Tuple[Arr]]:
    '''
    If index is of type signature `Tuple[Tensor]`, converts it to `Tuple[Arr]`.
    '''
    pass

def _getitem(x: Arr, index: Index) -> Arr:
    '''Like x[index] when x is a torch.Tensor.'''
    pass

def getitem_back(grad_out: Arr, out: Arr, x: Arr, index: Index):
    '''
    Backwards function for _getitem.

    Hint: use np.add.at(a, indices, b)
    This function works just like a[indices] += b, except that it allows for repeated indices.
    '''
    pass


getitem = wrap_forward_fn(_getitem)
BACK_FUNCS.add_back_func(_getitem, 0, getitem_back)

tests.test_coerce_index(coerce_index, Tensor)
tests.test_getitem_int(Tensor)
tests.test_getitem_tuple(Tensor)
tests.test_getitem_integer_array(Tensor)
tests.test_getitem_integer_tensor(Tensor)
```

<details>
<summary>Help - I'm confused about how to implement getitem_back.</summary>

If no coordinates were repeated, we could just assign the grad for each input element to be the grad at the corresponding output position, or 0 if that input element didn't appear.

Because of the potential for repeat coordinates, we need to sum the grad from each corresponding output position.

Initialize an array of zeros of the same shape as x, and then write in the appropriate elements using `np.add.at`.
</details>

<details>
<summary>Solution</summary>


```python
def coerce_index(index: Index) -> Union[int, Tuple[int, ...], Tuple[Arr]]:
    '''
    If index is of type signature `Tuple[Tensor]`, converts it to `Tuple[Arr]`.
    '''
    # SOLUTION
    if isinstance(index, tuple) and set(map(type, index)) == {Tensor}:
        return tuple([i.array for i in index])
    else:
        return index

def _getitem(x: Arr, index: Index) -> Arr:
    '''Like x[index] when x is a torch.Tensor.'''
    # SOLUTION
    return x[coerce_index(index)]

def getitem_back(grad_out: Arr, out: Arr, x: Arr, index: Index):
    '''
    Backwards function for _getitem.

    Hint: use np.add.at(a, indices, b)
    This function works just like a[indices] += b, except that it allows for repeated indices.
    '''
    # SOLUTION
    new_grad_out = np.full_like(x, 0)
    np.add.at(new_grad_out, coerce_index(index), grad_out)
    return new_grad_out
```
</details>


### elementwise add, subtract, divide

```yaml
Difficulty: ðŸ”´ðŸ”´ðŸ”´âšªâšª
Importance: ðŸ”µðŸ”µâšªâšªâšª

You should spend up to 10-15 minutes on this exercise.
```

These are exactly analogous to the multiply case. Note that Python and NumPy have the notion of "floor division", which is a truncating integer division as in `7 // 3 = 2`. You can ignore floor division: - we only need the usual floating point division which is called "true division". 

Use lambda functions to define and register the backward functions each in one line. If you're confused, you can click on the expander below to reveal the first one.


<details>
<summary>Reveal the first one:</summary>

```python
BACK_FUNCS.add_back_func(np.add, 0, lambda grad_out, out, x, y: unbroadcast(grad_out, x))
```
</details>


```python
add = wrap_forward_fn(np.add)
subtract = wrap_forward_fn(np.subtract)
true_divide = wrap_forward_fn(np.true_divide)

# Your code here - add to the BACK_FUNCS object

tests.test_add_broadcasted(Tensor)
tests.test_subtract_broadcasted(Tensor)
tests.test_truedivide_broadcasted(Tensor)
```

<details>
<summary>Solution (backward funcs)</summary>

```python
BACK_FUNCS.add_back_func(np.add, 0, lambda grad_out, out, x, y: unbroadcast(grad_out, x))
BACK_FUNCS.add_back_func(np.add, 1, lambda grad_out, out, x, y: unbroadcast(grad_out, y))
BACK_FUNCS.add_back_func(np.subtract, 0, lambda grad_out, out, x, y: unbroadcast(grad_out, x))
BACK_FUNCS.add_back_func(np.subtract, 1, lambda grad_out, out, x, y: unbroadcast(-grad_out, y))
BACK_FUNCS.add_back_func(np.true_divide, 0, lambda grad_out, out, x, y: unbroadcast(grad_out/y, x))
BACK_FUNCS.add_back_func(np.true_divide, 1, lambda grad_out, out, x, y: unbroadcast(grad_out*(-x/y**2), y))
```
</details>


## In-Place Operations

Supporting in-place operations introduces substantial complexity and generally doesn't help performance that much. The problem is that if any of the inputs used in the backward function have been modified in-place since the forward pass, then the backward function will incorrectly calculate using the modified version.

PyTorch will warn you when this causes a problem with the error "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.".

You can implement the warning in the bonus section but for now your system will silently compute the wrong gradients - user beware!

(note - you don't have to fill anything in here; just run the cell)


```python
def add_(x: Tensor, other: Tensor, alpha: float = 1.0) -> Tensor:
    '''Like torch.add_. Compute x += other * alpha in-place and return tensor.'''
    np.add(x.array, other.array * alpha, out=x.array)
    return x


def safe_example():
    '''This example should work properly.'''
    a = Tensor([0.0, 1.0, 2.0, 3.0], requires_grad=True)
    b = Tensor([2.0, 3.0, 4.0, 5.0], requires_grad=True)
    a.add_(b)
    c = a * b
    c.sum().backward()
    assert a.grad is not None and np.allclose(a.grad.array, [2.0, 3.0, 4.0, 5.0])
    assert b.grad is not None and np.allclose(b.grad.array, [2.0, 4.0, 6.0, 8.0])


def unsafe_example():
    '''This example is expected to compute the wrong gradients.'''
    a = Tensor([0.0, 1.0, 2.0, 3.0], requires_grad=True)
    b = Tensor([2.0, 3.0, 4.0, 5.0], requires_grad=True)
    c = a * b
    a.add_(b)
    c.sum().backward()
    if a.grad is not None and np.allclose(a.grad.array, [2.0, 3.0, 4.0, 5.0]):
        print("Grad wrt a is OK!")
    else:
        print("Grad wrt a is WRONG!")
    if b.grad is not None and np.allclose(b.grad.array, [0.0, 1.0, 2.0, 3.0]):
        print("Grad wrt b is OK!")
    else:
        print("Grad wrt b is WRONG!")



safe_example()
unsafe_example()
```

## Mixed Scalar-Tensor Operations

You may have been wondering why our `Tensor` class has to define both `__mul__` and `__rmul__` magic methods.

Without `__rmul__` defined, executing `2 * a` when `a` is a `Tensor` would try to call `2.__mul__(a)`, and the built-in class `int` would be confused about how to handle this. 

Since we have defined `__rmul__` for you at the start, and you implemented multiply to work with floats as arguments, the following should "just work".


```python
a = Tensor([0, 1, 2, 3], requires_grad=True)
(a * 2).sum().backward()
b = Tensor([0, 1, 2, 3], requires_grad=True)
(2 * b).sum().backward()
assert a.grad is not None
assert b.grad is not None
assert np.allclose(a.grad.array, b.grad.array)
```

### Exercise - `max`

```yaml
Difficulty: ðŸ”´ðŸ”´ðŸ”´âšªâšª
Importance: ðŸ”µðŸ”µâšªâšªâšª

You should spend up to 10-15 minutes on this exercise.
```

Since this is an elementwise function, we can think about the scalar case. For scalar $x$, $y$, the derivative for $\max(x, y)$ wrt $x$ is 1 when $x > y$ and 0 when $x < y$. What should happen when $x = y$?

Intuitively, since $\max(x, x)$ is equivalent to the identity function which has a derivative of 1 wrt $x$, it makes sense for the sum of our partial derivatives wrt $x$ and $y$ to also therefore total 1. The convention used by PyTorch is to split the derivative evenly between the two arguments. We will follow this behavior for compatibility, but it's just as legitimate to say it's 1 wrt $x$ and 0 wrt $y$, or some other arbitrary combination that sums to one.


<details>
<summary>Help - I'm not sure how to implement this function.</summary>

Try returning `grad_out * bool_sum`, where `bool_sum` is an array constructed from the sum of two boolean arrays.

You can alternatively use `np.where`.
</details>

<details>
<summary>Help - I'm passing the first test but not the second.</summary>

This probably means that you haven't implemented `unbroadcast`. You'll need to do this, to get `grad_out` into the right shape before you use it in `np.where`.
</details>


```python
def maximum_back0(grad_out: Arr, out: Arr, x: Arr, y: Arr):
    '''Backwards function for max(x, y) wrt x.'''
    pass

def maximum_back1(grad_out: Arr, out: Arr, x: Arr, y: Arr):
    '''Backwards function for max(x, y) wrt y.'''
    pass


maximum = wrap_forward_fn(np.maximum)

BACK_FUNCS.add_back_func(np.maximum, 0, maximum_back0)
BACK_FUNCS.add_back_func(np.maximum, 1, maximum_back1)

tests.test_maximum(Tensor)
tests.test_maximum_broadcasted(Tensor)
```

<details>
<summary>Solution</summary>


```python
def maximum_back0(grad_out: Arr, out: Arr, x: Arr, y: Arr):
    '''Backwards function for max(x, y) wrt x.'''
    # SOLUTION
    bool_sum = ((x > y) + 0.5 * (x == y))
    return unbroadcast(grad_out * bool_sum, x)

def maximum_back1(grad_out: Arr, out: Arr, x: Arr, y: Arr):
    '''Backwards function for max(x, y) wrt y.'''
    # SOLUTION
    bool_sum = ((x < y) + 0.5 * (x == y))
    return unbroadcast(grad_out * bool_sum, y)
```
</details>


### Exercise - functional `ReLU`

```yaml
Difficulty: ðŸ”´ðŸ”´âšªâšªâšª
Importance: ðŸ”µðŸ”µâšªâšªâšª

You should spend up to 10-15 minutes on this exercise.
```

A simple and correct ReLU function can be defined in terms of your maximum function. Note the PyTorch version also supports in-place operation, which we are punting on for now.

Again, at $x = 0$ your derivative could reasonably be anything between 0 and 1 inclusive, but we've followed PyTorch in making it 0.5.



```python
def relu(x: Tensor) -> Tensor:
    '''Like torch.nn.function.relu(x, inplace=False).'''
    pass


tests.test_relu(Tensor)
```

<details>
<summary>Solution</summary>

```python
def relu(x: Tensor) -> Tensor:
    '''Like torch.nn.function.relu(x, inplace=False).'''
    # SOLUTION
    return maximum(x, 0.0)
```
</details>


### Exercise - 2D `matmul`

```yaml
Difficulty: ðŸ”´ðŸ”´ðŸ”´ðŸ”´âšª
Importance: ðŸ”µðŸ”µðŸ”µâšªâšª

You should spend up to 20-25 minutes on this exercise.
```

Implement your version of `torch.matmul`, restricting it to the simpler case where both inputs are 2D.


```python
def _matmul2d(x: Arr, y: Arr) -> Arr:
    '''Matrix multiply restricted to the case where both inputs are exactly 2D.'''
    return x @ y

def matmul2d_back0(grad_out: Arr, out: Arr, x: Arr, y: Arr) -> Arr:
    pass

def matmul2d_back1(grad_out: Arr, out: Arr, x: Arr, y: Arr) -> Arr:
    pass


matmul = wrap_forward_fn(_matmul2d)
BACK_FUNCS.add_back_func(_matmul2d, 0, matmul2d_back0)
BACK_FUNCS.add_back_func(_matmul2d, 1, matmul2d_back1)

tests.test_matmul2d(Tensor)
```

<details>
<summary>Help - I'm confused about <code>matmul2d_back</code>!</summary>

Let $X$, $Y$ and $M$ denote the variables `x`, `y` and `out`, so we have the matrix relation $M = XY$. The object `grad_out` is a tensor with elements `grad_out[p, q]` $ = \frac{\partial L}{\partial M_{p q}}$. 

The output of `matmul2d_back0` should be the gradient of $L$ wrt $X$, i.e. it should have elements $\frac{\partial L}{\partial X_{i j}}$. Can you write this in terms of the elements of `x`, `y`, `out` and `grad_out`?
</details>

<details>
<summary>Help - I'm still stuck on <code>matmul2d_back</code>.</summary>

We can write $\frac{\partial L}{\partial X_{i j}}$ as:

$$
\begin{aligned}
\frac{\partial L}{\partial X_{i j}} &=\sum_{pq} \frac{\partial L}{\partial M_{p q}} \frac{\partial M_{p q}}{\partial X_{i j}} \\
&=\sum_{pq} \left[\text{ grad\_out }\right]_{p q} \frac{\partial (\sum_r X_{p r} Y_{r q})}{\partial X_{i j}} \quad\quad \text{ because } M_{pq} = \sum_r X_{pr} Y_{rq} \\
&=\sum_{pqr} \left[\text{ grad\_out }\right]_{p q}  \frac{\partial X_{p r}}{\partial X_{i j}} Y_{rq} \\
&=\sum_{q} \left[\text{ grad\_out }\right]_{iq} Y_{j q} \quad\quad \text{because } \frac{\partial{X_{pr}}}{X_{ij}} = 1 \text{ if } (p, r) = (i, j), \text{ else } 0 \\
&=\sum_{q} \left[\text{ grad\_out }\right]_{iq} Y^T_{qj} \\
&= \left[\text{ grad\_out } \times Y^{\top}\right]_{ij}
\end{aligned}
$$


In other words, the `x.grad` attribute should be is `grad_out @ y.T`.

You can calculate the gradient wrt `y` in a similar way - we leave this as an exercise for the reader.
</details>

<details>
<summary>Solution</summary>


```python
def matmul2d_back0(grad_out: Arr, out: Arr, x: Arr, y: Arr) -> Arr:
    # SOLUTION
    return grad_out @ y.T

def matmul2d_back1(grad_out: Arr, out: Arr, x: Arr, y: Arr) -> Arr:
    # SOLUTION
    return x.T @ grad_out
```
</details>




""", unsafe_allow_html=True)

