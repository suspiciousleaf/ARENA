import streamlit as st

def section():
    st.sidebar.markdown(
r"""
## Table of Contents

<ul class="contents">
    <li class='margtop'><a class='contents-el' href='#introduction'>Introduction</a></li>
    <li class='margtop'><a class='contents-el' href='#content-learning-objectives'>Content & Learning Objectives</a></li>
    <li><ul class="contents">
        <li><a class='contents-el' href='#1-introduction-to-nnsight'>Introduction to <code>nnsight</code></a></li>
        <li><a class='contents-el' href='#2-task-encoding-hidden-states'>Task-encoding hidden states</a></li>
        <li><a class='contents-el' href='#3-function-vectors'>Function Vectors</a></li>
        <li><a class='contents-el' href='#4-steering-vectors-in-gpt2-xl'>Steering Vectors in GPT2-XL</a></li>
        <li><a class='contents-el' href='#5-bonus'>Bonus</a></li>
    </ul></li>
    <li class='margtop'><a class='contents-el' href='#setup'>Setup</a></li>
</ul>""", unsafe_allow_html=True)
    
    st.markdown(
r"""
# [1.5] Function Vectors & Model Steering

### Colab: [**exercises**](https://colab.research.google.com/drive/1NYjR3tjOiDJ2v8nv3mhrph-_IM4p9goS?usp=sharing) | [**solutions**](https://colab.research.google.com/drive/1dQ-p8j_cCjHCQ82pc446vxxj5pNd2DvN?usp=sharing)

Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-28h0xs49u-ZN9ZDbGXl~oCorjbBsSQag), and ask any questions on the dedicated channels for this chapter of material.

If you want to flag specific errors / make suggestions regarding the `nnsight` library, you can [join the NDIF Discord group](https://discord.gg/QQQAM45b5z) and get involved!

> **Important note** - these exercises work with the `nnsight` library, which is currently still under development and may have occasional issues. If you're facing issues, you should try and change the argument `remote=True` to `remote=False` (this will require having compute equivalent to an A100; like you'd have in a Colab Pro+ subscription). We've defined a global `REMOTE` variable near the start of the exercises (default value is True).

You can toggle dark mode from the buttons on the top-right of this page.

Links to other chapters: [**(0) Fundamentals**](https://arena3-chapter0-fundamentals.streamlit.app/), [**(2) RL**](https://arena3-chapter2-rl.streamlit.app/).

<img src="https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/fv_header.png" width="350">

## Introduction

These exercises serve as an exploration of the following question: ***can we steer a model to produce different outputs / have a different behaviour, by intervening on the model's forward pass using vectors found by non gradient descent-based methods?***

The majority of the exercises focus on [function vectors](https://functions.baulab.info/): vectors which are extracted from forward passes on in-context learning (ICL) tasks, and added to the residual stream in order to trigger the execution of this task from a zero-shot prompt. The diagram below illustrates this.

<img src="https://functions.baulab.info/images/Paper/fv-demonstrations.png" width="650">

The exercises also take you through use of the `nnsight` library, which is designed to support this kind of work (and other interpretability research) on very large language models - i.e. larger than models like GPT2-Small which you might be used to at this point in the course.

The final set of exercises look at Alex Turner et al's work on [steering vectors](https://www.lesswrong.com/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector), which is conceptually related but has different aims and methodologies. We end by suggesting a few different further avenues to explore with this kind of work.

## Content & Learning Objectives

### 1️⃣ Introduction to `nnsight`

In this section, you'll learn the basics of how to use the `nnsight` library: running forward passes on your model, and saving the internal states. You'll also learn some basics of HuggingFace models which translate over into `nnsight` models (e.g. tokenization, and how to work with model output).

> ##### Learning Objectives
>
> * Learn the basics of the `nnsight` library, and what it can be useful for
> * Use it to extract & visualise GPT-J-6B's internal activations

### 2️⃣ Task-encoding hidden states

We'll begin with the following question, posed by the Function Vectors paper:

> *When a transformer processes an ICL (in-context-learning) prompt with exemplars demonstrating task $T$, do any hidden states encode the task itself?*

We'll prove that the answer is yes, by constructing a vector $h$ from a set of ICL prompts for the **antonym task**, and intervening with our vector to make our model produce antonyms on zero-shot prompts.

This will require you to learn how to perform causal interventions with `nnsight`, not just save activations.

(Note - this section structurally follows section 2.1 of the function vectors paper).

> ##### Learning Objectives
>
> * Understand how `nnsight` can be used to perform causal interventions, and perform some yourself
> * Reproduce the "h-vector results" from the function vectors paper; that the residual stream does contain a vector which encodes the task and can induce task behaviour on zero-shot prompts

### 3️⃣ Function Vectors

In this section, we'll replicate the crux of the paper's results, by identifying a set of attention heads whose outputs have a large effect on the model's ICL performance, and showing we can patch with these vectors to induce task-solving behaviour on randomly shuffled prompts.

We'll also learn how to use `nnsight` for multi-token generation, and steer the model's behaviour. There exist exercises where you can try this out for different tasks, e.g. the Country-Capitals task, where you'll be able to steer the model to complete prompts like `"When you think of Netherlands, you usually think of"` by talking about Amsterdam.

(Note - this section structurally follows sections 2.2, 2.3 and some of section 3 from the function vectors paper).

> ##### Learning Objectives
>
> * Define a metric to measure the causal effect of each attention head on the correct performance of the in-context learning task
> * Understand how to rearrange activations in a model during an `nnsight` forward pass, to extract activations corresponding to a particular attention head
> * Learn how to use `nnsight` for multi-token generation

### 4️⃣ Steering Vectors in GPT2-XL

Here, we discuss a different but related set of research: Alex Turner's work on steering vectors. This also falls under the umbrella of "interventions in the residual stream using vectors found with forward pass (non-SGD) based methods in order to alter behaviour", but it has a different setup, objectives, and approach.

> ##### Learning Objectives
>
> * Understand the goals & main results from Alex Turner et al's work on steering vectors
> * Reproduce the changes in behaviour described in their initial post

### 5️⃣ Bonus

Lastly, we discuss some possible extensions of function vectors & steering vectors work, which is currently an exciting area of development (e.g. with a paper on steering Llama 2-13b coming out as recently as December 2023).

```python
import time
from pathlib import Path
from typing import List, Optional, Tuple, Union
import circuitsvis as cv
import numpy as np
import openai
import plotly.express as px
import torch as t
import torch.nn as nn
import torch.nn.functional as F
from IPython.display import display
from jaxtyping import Float, Int
from rich import print as rprint
from rich.table import Table
from torch import Tensor
from tqdm import tqdm
import einops
import os
import sys
import gdown
import zipfile
from IPython.display import clear_output
from collections import defaultdict

import nnsight
from nnsight import LanguageModel
from nnsight.intervention import InterventionProxy

# Hide bunch of info logging messages from nnsight
import logging, warnings
logging.disable(sys.maxsize)
warnings.filterwarnings('ignore', category=UserWarning, module='huggingface_hub.utils._token')

device = t.device("cuda" if t.cuda.is_available() else "cpu")

t.set_grad_enabled(False);

# Make sure exercises are in the path
chapter = r"chapter1_transformer_interp"
exercises_dir = Path(f"{os.getcwd().split(chapter)[0]}/{chapter}/exercises").resolve()
section_dir = exercises_dir / "part5_function_vectors_and_model_steering"
if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))

from plotly_utils import imshow
import part5_function_vectors_and_model_steering.solutions as solutions
import part5_function_vectors_and_model_steering.tests as tests

device = t.device("cuda" if t.cuda.is_available() else "cpu")

MAIN = __name__ == '__main__'
```

""", unsafe_allow_html=True)